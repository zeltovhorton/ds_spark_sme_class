{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 10: Creating a Feature Matrix using Spark-ML Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As always, create a SparkContext/HiveContext."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set up Spark Context\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "SparkContext.setSystemProperty('spark.executor.memory', '2g')\n",
    "conf = SparkConf()\n",
    "conf.set('spark.executor.instances', 15)\n",
    "conf.set('spark.sql.autoBroadcastJoinThreshold', 200*1024*1024)  # 200MB for broadcast join\n",
    "sc = SparkContext('yarn-client', 'Spark-lab10', conf=conf)\n",
    "\n",
    "from pyspark.sql import HiveContext\n",
    "hc = HiveContext(sc)\n",
    "hc.sql(\"use demo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the crimes_wn table that was created in Lab 9 as a Spark Dataframe, and filter the dataset to include all records between 2011 and 2014:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "crimes_wn_all = <YOUR CODE HERE>\n",
    "crimes_wn = crimes_wn_all.filter(<YOUR CODE HERE>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creater a new data frame 'crimes' via feature transformations as follows:\n",
    "- Create features for 'year', 'month' and 'day' from the raw field 'date'\n",
    "- Create the 'hour' feature from the raw field 'time'\n",
    "- Create a feature 'resolved' from the 'resolution' field with a value of 0.0 if \"NONE\" and 1.0 otherwise\n",
    "- Include these other fields: category, district, dayofweek, description, neighborhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "crimes = crimes_wn.<YOUR CODE HERE>\n",
    "crimes.cache()\n",
    "crimes.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create the weather dataframe that includes the precipitation, tmin and tmax for San Francisco for each day in the years 2011-2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weather = hc.<YOUR CODE HERE>\n",
    "prcp = weather.<YOUR CODE HERE>\n",
    "tmin = weather.<YOUR CODE HERE>\n",
    "tmax = weather.<YOUR CODE HERE>\n",
    "\n",
    "wdata = <YOUR CODE HERE>\n",
    "wdata.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join the resulting weather dataset with the crimes dataset, using the join key (year,month,day). \n",
    "* create a dataframe \"joined\" that joins the two dataframes (crimes and weather)\n",
    "* In the joined dataset the year, month and day fields appear twice. Create a python list \"keep\" that includes the names of the fields that we would like to keep from the joined result, then create the \"fm\" dataframe by selecting those fields only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "joined = <YOUR CODE HERE>\n",
    "keep = <YOUR CODE HERE>\n",
    "fm = joined.select(*keep).cache()\n",
    "\n",
    "fm.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Store this feature matrix into HDFS, so that you can use it in the next lab. This is not strictly necessary when using Spark since a DataFrame can be used sequentially for the next step, but useful in our case since our application is split into individual labs.\n",
    "\n",
    "Use the DataFrames save() function with the ORC data source. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fm.write.format(\"orc\").save(\"/tmp/fm\", mode=\"overwrite\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
