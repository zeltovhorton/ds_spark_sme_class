{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 5.1: Data Persistence with Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore data persistence and caching and its importance in Spark performance tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set up Spark Context\n",
    "from pyspark import SparkContext, SparkConf\n",
    "\n",
    "SparkContext.setSystemProperty('spark.executor.memory', '2g')\n",
    "conf = SparkConf()\n",
    "conf.set('spark.executor.instances', 15)\n",
    "sc = SparkContext('yarn-client', 'Spark-lab5.1', conf=conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an RDD with weather data, with the following 4 fields: station, date, metric and value. Load only the year 2013 from this dataset - the file for year 2013 resides in /user/jupyter/weather/2013.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "lines = sc.textFile(\"weather/2013.csv\")\n",
    "weather = lines.map(lambda line: line.split(',')) \\\n",
    "               .map(lambda row: [row[0], row[1], row[2], row[3]])  # schema: station, date, metric type, value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without caching any data, use Spark to compute the maximum and minimum values of TMIN during 2013. \n",
    "\n",
    "Use IPython's \"%%timeit\" to measure the time it takes Spark to execute both queries. \n",
    "Note: \"%%timtit\" runs the cell in a loop, and thus all variables inside the cell are NOT available in later cells.\n",
    "\n",
    "More details on %%timeit are here: https://ipython.org/ipython-doc/dev/interactive/magics.html#magic-timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-994\n",
      "7111\n",
      "1 loops, best of 1: 1min 8s per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n1 -r1\n",
    "\n",
    "wf = weather.filter(lambda row: row[2]=='TMIN').map(lambda row: int(row[3]))\n",
    "print wf.min()\n",
    "print wf.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now run this again, this time use cache() to optimize performance and measure again using \"%%timeit\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-994\n",
      "7111\n",
      "1 loops, best of 1: 33.8 s per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n1 -r1\n",
    "\n",
    "wf = weather.filter(lambda row: row[2]=='TMIN').map(lambda row: int(row[3])).cache()\n",
    "print wf.min()\n",
    "print wf.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Check Spark UI for the jobs execution time. See how the caching improved the run-time of the second operation.\n",
    "\n",
    "Next, determine how many partitions exist for the weather dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather.getNumPartitions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print out the number of items in each partition (use mapPartitionsWithIndex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 3813172), (1, 3817869), (2, 3824474), (3, 3815669), (4, 3814805), (5, 3824935), (6, 3833317), (7, 3155909)]\n"
     ]
    }
   ],
   "source": [
    "print weather.mapPartitionsWithIndex(lambda index,iterator: ((index,sum(1 for _ in iterator)),)).collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
