{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 5.2: Joins with Spark-Core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup your spark Context:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set up Spark Context\n",
    "from pyspark import SparkContext, SparkConf\n",
    "\n",
    "SparkContext.setSystemProperty('spark.executor.memory', '2g')\n",
    "conf = SparkConf()\n",
    "conf.set('spark.executor.instances', 15)\n",
    "sc = SparkContext('yarn-client', 'Spark-lab5.2', conf=conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the crimes dataset and weather dataset into two RDDs.   \n",
    "* The weather file for year 2013 resides under weather/2013.csv (as before, only load the year 2013)\n",
    "* The crimes dataset file resides in crime_report/sf_crimes.csv. Use Python's csv.reader to read the text fields in the crimes dataset to avoid problems of commas inside a text field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29900150 weather readings\n",
      "1750133 crime events\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from csv import reader\n",
    "\n",
    "# Weather dataset\n",
    "w_lines = sc.textFile(\"weather/2013.csv\")\n",
    "weather = w_lines.map(lambda line: line.split(',')) \\\n",
    "                 .map(lambda row: [row[0], row[1], row[2], row[3]]).cache()\n",
    "print \"%s weather readings\" % weather.count()\n",
    "\n",
    "# Crimes dataset\n",
    "c_lines = sc.textFile(\"crime_report/sf_crimes.csv\") \\\n",
    "            .filter(lambda line: line[:2]!='In')\n",
    "crimes = c_lines.map(lambda line: [x.strip('\"') for x in next(reader([line]))]).cache()\n",
    "print \"%s crime events\" % crimes.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the RDD lineage graph of \"crimes\" and \"weather\" using toDebugString()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crimes\n",
      "(3) PythonRDD[6] at RDD at PythonRDD.scala:43 [Memory Serialized 1x Replicated]\n",
      " |       CachedPartitions: 3; MemorySize: 242.5 MB; ExternalBlockStoreSize: 0.0 B; DiskSize: 0.0 B\n",
      " |  MapPartitionsRDD[5] at textFile at NativeMethodAccessorImpl.java:-2 [Memory Serialized 1x Replicated]\n",
      " |  crime_report/sf_crimes.csv HadoopRDD[4] at textFile at NativeMethodAccessorImpl.java:-2 [Memory Serialized 1x Replicated]\n",
      "\n",
      "\n",
      "weather\n",
      "(8) PythonRDD[2] at RDD at PythonRDD.scala:43 [Memory Serialized 1x Replicated]\n",
      " |       CachedPartitions: 8; MemorySize: 938.6 MB; ExternalBlockStoreSize: 0.0 B; DiskSize: 0.0 B\n",
      " |  MapPartitionsRDD[1] at textFile at NativeMethodAccessorImpl.java:-2 [Memory Serialized 1x Replicated]\n",
      " |  weather/2013.csv HadoopRDD[0] at textFile at NativeMethodAccessorImpl.java:-2 [Memory Serialized 1x Replicated]\n"
     ]
    }
   ],
   "source": [
    "print \"crimes\"\n",
    "print crimes.toDebugString()\n",
    "\n",
    "print \"\\n\\nweather\"\n",
    "print weather.toDebugString()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that the weather dataset schema is: station, date, metric, value\n",
    "\n",
    "Create an RDD from the weather dataset for the PRCP metric:\n",
    "1. Use only weather station USW00023272 (San Francisco)\n",
    "2. Each row in the new RDD should contain: date, value\n",
    "\n",
    "print 3 example values from the new RDD. How many elements exist in this new RDD?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'20130101', u'0'), (u'20130102', u'0'), (u'20130103', u'0')]\n",
      "365\n"
     ]
    }
   ],
   "source": [
    "weather_kv = weather.filter(lambda x: x[0]=='USW00023272').filter(lambda x: x[2] == 'PRCP') \\\n",
    "                      .map(lambda x: (x[1],x[3]))\n",
    "print weather_kv.take(3)\n",
    "print weather_kv.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To enable a join between the crime and weather datsets, create an RDD from the crimes dataset. This new RDD will have a key-value tuple, where:\n",
    "* The key is the date in a similar format to that of the weather dataset: YYYYMMDD\n",
    "* The value is the whole record from the crimes dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('20150422', ['150331521', 'LARCENY/THEFT', 'GRAND THEFT FROM A BUILDING', 'Wednesday', '04/22/2015', '18:00', 'BAYVIEW', 'NONE', '2000 Block of EVANS AV', '-122.396315619126', '37.7478113603031', '(37.7478113603031, -122.396315619126)', '15033152106304']), ('20150419', ['150341605', 'ASSAULT', 'ATTEMPTED SIMPLE ASSAULT', 'Sunday', '04/19/2015', '12:15', 'CENTRAL', 'NONE', '800 Block of WASHINGTON ST', '-122.40672716771', '37.7950566945259', '(37.7950566945259, -122.40672716771)', '15034160504114']), ('20150419', ['150341605', 'ASSAULT', 'THREATS AGAINST LIFE', 'Sunday', '04/19/2015', '12:15', 'CENTRAL', 'NONE', '800 Block of WASHINGTON ST', '-122.40672716771', '37.7950566945259', '(37.7950566945259, -122.40672716771)', '15034160519057'])]\n"
     ]
    }
   ],
   "source": [
    "crimes_kv = crimes.map(lambda x: (''.join([x[4][6:],x[4][:2],x[4][3:5]]), x))\n",
    "print crimes_kv.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join the crimes and weather RDDs, the output having prcp data for each crime report event. Print a few records of the resulting RDD to validate your approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         category                                  description        date  \\\n",
      "0  OTHER OFFENSES        DRIVERS LICENSE, SUSPENDED OR REVOKED  08/26/2013   \n",
      "1       VANDALISM    MALICIOUS MISCHIEF, VANDALISM OF VEHICLES  08/26/2013   \n",
      "2   LARCENY/THEFT                  GRAND THEFT FROM A BUILDING  08/26/2013   \n",
      "3   LARCENY/THEFT                 GRAND THEFT FROM LOCKED AUTO  08/26/2013   \n",
      "4        BURGLARY  BURGLARY OF APARTMENT HOUSE, FORCIBLE ENTRY  08/26/2013   \n",
      "\n",
      "    district     resolution                               location prcp  \n",
      "0   SOUTHERN  ARREST, CITED   (37.775420706711, -122.403404791479)    0  \n",
      "1  INGLESIDE           NONE  (37.7448909444398, -122.432375194686)    0  \n",
      "2    MISSION           NONE  (37.7624209454461, -122.430625527042)    0  \n",
      "3   SOUTHERN           NONE  (37.7801398610181, -122.405488408396)    0  \n",
      "4    MISSION           NONE  (37.7542221906773, -122.425236707185)    0  \n"
     ]
    }
   ],
   "source": [
    "j1 = crimes_kv.join(weather_kv)\n",
    "j2 = j1.map(lambda (k,v): v[0] + [v[1]])\n",
    "df1 = pd.DataFrame(j2.take(5), \\\n",
    "                   columns=['ID','category','description','dayofweek','date','time', \\\n",
    "                            'district','resolution','address','x','y','location','pdid', 'prcp'])\n",
    "df2 = df1[['category', 'description', 'date', 'district', 'resolution', 'location', 'prcp']]\n",
    "print df2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the join lineage information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11) PythonRDD[19] at RDD at PythonRDD.scala:43 []\n",
      " |   MapPartitionsRDD[17] at mapPartitions at PythonRDD.scala:374 []\n",
      " |   ShuffledRDD[16] at partitionBy at NativeMethodAccessorImpl.java:-2 []\n",
      " +-(11) PairwiseRDD[15] at join at <ipython-input-6-6c205b0c349d>:1 []\n",
      "    |   PythonRDD[14] at join at <ipython-input-6-6c205b0c349d>:1 []\n",
      "    |   UnionRDD[13] at union at NativeMethodAccessorImpl.java:-2 []\n",
      "    |   PythonRDD[11] at RDD at PythonRDD.scala:43 []\n",
      "    |   PythonRDD[6] at RDD at PythonRDD.scala:43 []\n",
      "    |       CachedPartitions: 3; MemorySize: 242.5 MB; ExternalBlockStoreSize: 0.0 B; DiskSize: 0.0 B\n",
      "    |   MapPartitionsRDD[5] at textFile at NativeMethodAccessorImpl.java:-2 []\n",
      "    |   crime_report/sf_crimes.csv HadoopRDD[4] at textFile at NativeMethodAccessorImpl.java:-2 []\n",
      "    |   PythonRDD[12] at RDD at PythonRDD.scala:43 []\n",
      "    |   PythonRDD[2] at RDD at PythonRDD.scala:43 []\n",
      "    |       CachedPartitions: 8; MemorySize: 938.6 MB; ExternalBlockStoreSize: 0.0 B; DiskSize: 0.0 B\n",
      "    |   MapPartitionsRDD[1] at textFile at NativeMethodAccessorImpl.java:-2 []\n",
      "    |   weather/2013.csv HadoopRDD[0] at textFile at NativeMethodAccessorImpl.java:-2 []\n"
     ]
    }
   ],
   "source": [
    "print j2.toDebugString()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
