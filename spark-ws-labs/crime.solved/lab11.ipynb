{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 11: Predictive model with Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As always, we create a SparkContext/HiveContext."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[result: string]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up Spark Context\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "SparkContext.setSystemProperty('spark.executor.memory', '2g')\n",
    "conf = SparkConf()\n",
    "conf.set('spark.executor.instances', 15)\n",
    "conf.set('spark.sql.autoBroadcastJoinThreshold', 100*1024*1024)  # 100MB for broadcast join\n",
    "sc = SparkContext('yarn-client', 'Spark-lab11', conf=conf)\n",
    "\n",
    "from pyspark.sql import HiveContext\n",
    "hc = HiveContext(sc)\n",
    "hc.sql(\"use demo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the feature matrix created in lab 10 into a Spark dataframe called 'fm', using the data frames Reader API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>prcp</th>\n",
       "      <th>tmin</th>\n",
       "      <th>tmax</th>\n",
       "      <th>hour</th>\n",
       "      <th>resolved</th>\n",
       "      <th>category</th>\n",
       "      <th>district</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>description</th>\n",
       "      <th>neighborhood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>135</td>\n",
       "      <td>67</td>\n",
       "      <td>94</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>OTHER OFFENSES</td>\n",
       "      <td>PARK</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>FALSE PERSONATION</td>\n",
       "      <td>Haight Ashbury</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>135</td>\n",
       "      <td>67</td>\n",
       "      <td>94</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>SUSPICIOUS OCC</td>\n",
       "      <td>TENDERLOIN</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>SUSPICIOUS OCCURRENCE</td>\n",
       "      <td>Downtown/Civic Center</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>135</td>\n",
       "      <td>67</td>\n",
       "      <td>94</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>DRUG/NARCOTIC</td>\n",
       "      <td>TENDERLOIN</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>POSSESSION OF MARIJUANA</td>\n",
       "      <td>Downtown/Civic Center</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>135</td>\n",
       "      <td>67</td>\n",
       "      <td>94</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>FRAUD</td>\n",
       "      <td>NORTHERN</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>CREDIT CARD, THEFT BY USE OF</td>\n",
       "      <td>Downtown/Civic Center</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>135</td>\n",
       "      <td>67</td>\n",
       "      <td>94</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>OTHER OFFENSES</td>\n",
       "      <td>BAYVIEW</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>FALSE PERSONATION TO RECEIVE MONEY OR PROPERTY</td>\n",
       "      <td>Excelsior</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  month  day  prcp  tmin  tmax  hour  resolved        category  \\\n",
       "0  2011      1    1   135    67    94     9         1  OTHER OFFENSES   \n",
       "1  2011      1    1   135    67    94    22         0  SUSPICIOUS OCC   \n",
       "2  2011      1    1   135    67    94    19         1   DRUG/NARCOTIC   \n",
       "3  2011      1    1   135    67    94     0         0           FRAUD   \n",
       "4  2011      1    1   135    67    94     0         0  OTHER OFFENSES   \n",
       "\n",
       "     district dayofweek                                     description  \\\n",
       "0        PARK  Saturday                               FALSE PERSONATION   \n",
       "1  TENDERLOIN  Saturday                           SUSPICIOUS OCCURRENCE   \n",
       "2  TENDERLOIN  Saturday                         POSSESSION OF MARIJUANA   \n",
       "3    NORTHERN  Saturday                    CREDIT CARD, THEFT BY USE OF   \n",
       "4     BAYVIEW  Saturday  FALSE PERSONATION TO RECEIVE MONEY OR PROPERTY   \n",
       "\n",
       "            neighborhood  \n",
       "0         Haight Ashbury  \n",
       "1  Downtown/Civic Center  \n",
       "2  Downtown/Civic Center  \n",
       "3  Downtown/Civic Center  \n",
       "4              Excelsior  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fm = hc.read.format(\"orc\").load(\"/tmp/fm\")\n",
    "fm.limit(5).toPandas()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the dataset into a training and testing set as follows:\n",
    "1. Use years 2011-2013 for training your model.\n",
    "2. use the year 2014 as your test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426306 150155\n"
     ]
    }
   ],
   "source": [
    "trainData = fm.filter(fm.year<=2013)\n",
    "testData = fm.filter(fm.year>=2014)\n",
    "\n",
    "print trainData.count(), testData.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Spark ML's pipeline API, create the components of an end-to-end pipeline as follows:\n",
    "1. Use the StringIndexer() transformation to convert all string variables (category, dayofweek, district, neighborhood) into categorical variables\n",
    "2. Similarly, convert the \"resolved\" variable to a categorical variable called \"label\". We need to do this since Spark-ML Logistic Regression requires a categorical variable as the target variable, whereas \"resolved\" is a numerical variable with values 0.0 and 1.0.\n",
    "3. Use VectorAssembler to create a \"features\" column that combines all the features of the model: month, hour, prcp, tmin, tmax, and the other categorical variables. Call the output column \"features\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "inx1 = StringIndexer(inputCol=\"category\", outputCol=\"cat-inx\")\n",
    "inx2 = StringIndexer(inputCol=\"dayofweek\", outputCol=\"dow-inx\")\n",
    "inx3 = StringIndexer(inputCol=\"district\", outputCol=\"dis-inx\")\n",
    "inx4 = StringIndexer(inputCol=\"neighborhood\", outputCol=\"ngh-inx\")\n",
    "inx5 = StringIndexer(inputCol=\"resolved\", outputCol=\"label\")\n",
    "vecAssembler = VectorAssembler(inputCols =[\"month\", \"hour\", \"prcp\", \"tmin\", \"tmax\", \\\n",
    "                                           \"cat-inx\", \"dow-inx\", \"dis-inx\", \"ngh-inx\"], \n",
    "                               outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a Logistic Regression classifier with reasonable paramter settings such as maxIter=30 and regParam=0.01:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "lr = LogisticRegression(maxIter=30, regParam=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the spark-ML pipeline to combine all the processing steps. Then train the model using the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline_lr = Pipeline(stages=[inx1, inx2, inx3, inx4, inx5, vecAssembler, lr])\n",
    "model_lr = pipeline_lr.fit(trainData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the predictions using the testData:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results = model_lr.transform(testData).cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a Pandas data frame from your results data frame, and use the eval_metrics function to compute the precision, recall and accuracy of the current model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eval_metrics(lap):\n",
    "    tp = float(len(lap[(lap['label']==1) & (lap['prediction']==1)]))\n",
    "    tn = float(len(lap[(lap['label']==0) & (lap['prediction']==0)]))\n",
    "    fp = float(len(lap[(lap['label']==0) & (lap['prediction']==1)]))\n",
    "    fn = float(len(lap[(lap['label']==1) & (lap['prediction']==0)]))\n",
    "    precision = tp / (tp+fp)\n",
    "    recall = tp / (tp+fn)\n",
    "    accuracy = (tp+tn) / (tp+tn+fp+fn)\n",
    "    return {'precision': precision, 'recall': recall, 'accuracy': accuracy}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this function to compute the precision, recall and accuracy of the current model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'recall': 0.15723408940761946, 'precision': 0.5328358208955224, 'accuracy': 0.6441277346741701}\n"
     ]
    }
   ],
   "source": [
    "lap = results.select(\"label\", \"prediction\").toPandas()\n",
    "print eval_metrics(lap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With Logistic Regression, you can print the trained model's weights and intercept coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.0229020936192,-0.00106710516373,-0.000454037952796,0.000157987875918,0.000136662126704,0.0507473781292,0.00523966744931,0.0450667138353,-0.0398805346853]\n",
      "-0.427123334573\n"
     ]
    }
   ],
   "source": [
    "print model_lr.stages[-1].weights\n",
    "print model_lr.stages[-1].intercept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the recall is relatively low. One possible cause for this might be that our categorical variables are represented as numerical values in our regression model. Create a different Spark-ML pipeline that uses OneHotEncoder to transform some of these categorical variables into dummy variables and re-run the logistic regression model. \n",
    "\n",
    "Did the results improve?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'recall': 0.6437825735887837, 'precision': 0.7542678993764782, 'accuracy': 0.794612234024841}\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import OneHotEncoder\n",
    "\n",
    "inx1 = StringIndexer(inputCol=\"category\", outputCol=\"cat-inx\")\n",
    "ohe1 = OneHotEncoder(inputCol=\"cat-inx\", outputCol=\"cat-ohe\")\n",
    "inx2 = StringIndexer(inputCol=\"dayofweek\", outputCol=\"dow-inx\")\n",
    "inx3 = StringIndexer(inputCol=\"district\", outputCol=\"dis-inx\")\n",
    "ohe3 = OneHotEncoder(inputCol=\"dis-inx\", outputCol=\"dis-ohe\")\n",
    "inx4 = StringIndexer(inputCol=\"neighborhood\", outputCol=\"ngh-inx\")\n",
    "ohe4 = OneHotEncoder(inputCol=\"ngh-inx\", outputCol=\"ngh-ohe\")\n",
    "inx5 = StringIndexer(inputCol=\"resolved\", outputCol=\"label\")\n",
    "vecAssembler = VectorAssembler(inputCols =[\"month\", \"hour\", \"prcp\", \"tmin\", \"tmax\", \\\n",
    "                                           \"cat-ohe\", \"dow-inx\", \"dis-ohe\", \"ngh-ohe\"], \n",
    "                               outputCol=\"features\")\n",
    "\n",
    "lr = LogisticRegression(maxIter=30)\n",
    "lr.setFitIntercept(True)\n",
    "pipeline_lr = Pipeline(stages=[inx1, ohe1, inx2, inx3, ohe3, inx4, ohe4, inx5, vecAssembler, lr])\n",
    "model_lr = pipeline_lr.fit(trainData)\n",
    "results = model_lr.transform(testData).cache()\n",
    "lap = results.select(\"label\", \"prediction\").toPandas()\n",
    "print eval_metrics(lap)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
