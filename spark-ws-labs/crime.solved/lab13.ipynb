{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 13: Selecting a model with Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As always, we create a SparkContext/HiveContext."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[result: string]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up Spark Context\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "SparkContext.setSystemProperty('spark.executor.memory', '2g')\n",
    "conf = SparkConf()\n",
    "conf.set('spark.executor.instances', 15)\n",
    "conf.set('spark.sql.autoBroadcastJoinThreshold', 100*1024*1024)  # 100MB for broadcast join\n",
    "sc = SparkContext('yarn-client', 'Spark-lab13', conf=conf)\n",
    "\n",
    "from pyspark.sql import HiveContext\n",
    "hc = HiveContext(sc)\n",
    "hc.sql(\"use demo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eval_metrics(lap):\n",
    "    tp = float(len(lap[(lap['label']==1) & (lap['prediction']==1)]))\n",
    "    tn = float(len(lap[(lap['label']==0) & (lap['prediction']==0)]))\n",
    "    fp = float(len(lap[(lap['label']==0) & (lap['prediction']==1)]))\n",
    "    fn = float(len(lap[(lap['label']==1) & (lap['prediction']==0)]))\n",
    "    precision = tp / (tp+fp)\n",
    "    recall = tp / (tp+fn)\n",
    "    accuracy = (tp+tn) / (tp+tn+fp+fn)\n",
    "    return {'precision': precision, 'recall': recall, 'accuracy': accuracy}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, prepare the training and testing datasets:\n",
    "1. Load the feature matrix created in lab 10 into a Spark dataframe called 'fm'\n",
    "2. Split into two dataframes - train (2011-2013) and test (only 2014)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426306 150155\n"
     ]
    }
   ],
   "source": [
    "fm = hc.read.format(\"orc\").load(\"/tmp/fm\")\n",
    "trainData = fm.filter(fm.year<=2013).cache()\n",
    "testData = fm.filter(fm.year>=2014).cache()\n",
    "print trainData.count(), testData.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in lab 12, build instances of the StringIndexer() and OneHotEncoder() for each of the variables, then combine them with a VectorAssembler:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer, VectorAssembler, OneHotEncoder\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# Build pre-process pipeline\n",
    "inx1 = StringIndexer(inputCol=\"category\", outputCol=\"cat-inx\")\n",
    "ohe1 = OneHotEncoder(inputCol=\"cat-inx\", outputCol=\"cat-ohe\")\n",
    "inx2 = StringIndexer(inputCol=\"dayofweek\", outputCol=\"dow-inx\")\n",
    "inx3 = StringIndexer(inputCol=\"district\", outputCol=\"dis-inx\")\n",
    "ohe3 = OneHotEncoder(inputCol=\"dis-inx\", outputCol=\"dis-ohe\")\n",
    "inx4 = StringIndexer(inputCol=\"neighborhood\", outputCol=\"ngh-inx\")\n",
    "ohe4 = OneHotEncoder(inputCol=\"ngh-inx\", outputCol=\"ngh-ohe\")\n",
    "inx5 = StringIndexer(inputCol=\"resolved\", outputCol=\"label\")\n",
    "vecAssembler = VectorAssembler(inputCols =[\"month\", \"hour\", \"prcp\", \"tmin\", \"tmax\", \\\n",
    "                                           \"cat-ohe\", \"dow-inx\", \"dis-ohe\", \"ngh-ohe\"], \n",
    "                               outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now build the complete feature generation and cross validation pipeline:\n",
    "* Build a CrossValidator instance using LogisticRegression and a paramter grid. In your paramter grid, test the values [0.1, 0.5, 1.0, 5.0] for regularization paramter, and the values [0.0, 0.5, 1.0] for the elasticNetParam.\n",
    "* Build a pipeline with all the stages plus the cross validator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "\n",
    "# Build a parameter grid\n",
    "cvlr = LogisticRegression(maxIter=100)\n",
    "grid = (ParamGridBuilder() \n",
    "      .addGrid(cvlr.regParam, [0.1, 0.5, 1.0, 5.0]) \n",
    "      .addGrid(cvlr.elasticNetParam, [0.0, 0.5, 1.0])\n",
    "      .build())\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"label\", metricName=\"areaUnderROC\")\n",
    "cv = CrossValidator(estimator=cvlr, estimatorParamMaps=grid, evaluator=evaluator, numFolds=3)\n",
    "\n",
    "pipe = Pipeline(stages=[inx1, ohe1, inx2, inx3, ohe3, inx4, ohe4, inx5, vecAssembler, cv])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the end-to-end pipeline:\n",
    "* Store the output of fit() in a variable called \"model\"\n",
    "* Apply the fitted model to the test data\n",
    "* Compute and print the resulting metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best AUC-ROC = 0.856759254037\n",
      "{'recall': 0.6437825735887837, 'precision': 0.7542678993764782, 'accuracy': 0.794612234024841}\n"
     ]
    }
   ],
   "source": [
    "model = pipe.fit(trainData)\n",
    "results = model.transform(testData).cache()\n",
    "\n",
    "print \"best AUC-ROC = \" + str(evaluator.evaluate(results))\n",
    "print eval_metrics(results.select('label', 'prediction').toPandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"model\" variable is of type PipelineModel and includes the fitted stages of each stage in the pipeline. We can look at the final stage (our cross-validation model) and print the intercept and weights for the best model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.458344636827\n",
      "[-0.0102934663622,0.00186486807845,-0.000277850255898,9.44566319521e-06,3.79132490894e-05,-1.09280456456,0.94265170687,-0.138998073021,0.201484753953,-0.807486732899,1.42975298722,1.61689763216,-0.786750849599,-0.540394240524,-1.01792172534,1.13860515254,-0.505028230997,-0.662144957732,0.470656863239,1.23475401051,0.858532787717,1.54271132569,-0.0157658732218,1.57691393002,0.16008341433,1.1327439085,-0.927905915448,0.802523880701,1.69137349719,0.533984801236,0.754606678819,1.29404062587,-0.4861696308,-0.43524394352,1.25216721225,0.0652692747964,-0.153615230777,0.806075117836,-0.639106538216,-0.0855644889181,0.337007291552,0.724027149259,0.299620135111,0.00412397645252,0.0266695848157,0.0739579912159,-0.0996848824653,0.0356472363874,-0.195907402578,-0.0204346154383,0.402258491104,-0.0707766567344,-0.0364279346575,0.184874215397,0.042568107117,0.0650824648588,0.15908098627,-0.142024641044,0.00686666282156,-0.033788558764,0.160548419892,-0.0665190575756,-0.0055014329379,-0.00172500607764,-0.0135355806186,-0.164861919353,-0.195283885408,0.0173003248154,-0.25992554648,-0.145759448005,-0.00407116886357,-0.00857519322245,0.0383303465226,-0.226011864564,-0.129870976723,-0.160698392521,-0.20860027102,-0.370634902112,-0.202287442749,-0.107097731426,-0.0266244113066,-0.343239125905,-0.218872870844,-0.0163037628229,-0.285376798424,-0.499559669624,-0.470512005114,-0.25304105846,-0.371049534775]\n"
     ]
    }
   ],
   "source": [
    "bestModel = model.stages[9].bestModel\n",
    "print bestModel.intercept\n",
    "print bestModel.weights"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
